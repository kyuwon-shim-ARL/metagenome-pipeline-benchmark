# í˜„ì‹¤ì ì¸ ë²¤ì¹˜ë§ˆí¬ ì ‘ê·¼ ë°©ë²•

## 1. í˜„ì‹¤ ì²´í¬ âœ‹

### ì§€ê¸ˆê¹Œì§€ ë§Œë“  ê²ƒì˜ ë¬¸ì œì 
- **ê³¼ë„í•œ ì¶”ìƒí™”**: SDK, API, ëª¨ë“ˆ... ì‹¤ì œë¡œ êµ¬í˜„ëœ ê±´ ì—†ìŒ
- **Wrapperì˜ í•¨ì •**: Nextflowë¥¼ Pythonìœ¼ë¡œ ê°ì‹¸ëŠ” ë¶ˆí•„ìš”í•œ ë ˆì´ì–´
- **ë³µì¡ë„ ì¦ê°€**: ì˜¤íˆë ¤ ì§ì ‘ ì‹¤í–‰ë³´ë‹¤ ë³µì¡í•´ì§
- **ìœ ì§€ë³´ìˆ˜ ë¶€ë‹´**: Wrapper ìì²´ë¥¼ ê³„ì† ì—…ë°ì´íŠ¸í•´ì•¼ í•¨

### ì§„ì§œ í•„ìš”í•œ ê²ƒ
1. **íŒŒë¼ë¯¸í„° ì¡°í•© í…ŒìŠ¤íŠ¸**: ì–´ë–¤ ì¡°í•©ì´ ê°€ì¥ ì¢‹ì€ì§€
2. **ì‹¤í–‰ ì‹œê°„/ë©”ëª¨ë¦¬ ì¸¡ì •**: ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ íŒŒì•…
3. **ê²°ê³¼ ë¹„êµ**: ì–´ì…ˆë¸”ë¦¬ í’ˆì§ˆ, ë¹„ë‹ ê²°ê³¼ ë“±

## 2. ê°€ì¥ ë‹¨ìˆœí•˜ê³  ì‹¤ìš©ì ì¸ ë°©ë²•

### ë°©ë²• 1: ë‹¨ìˆœ Bash ìŠ¤í¬ë¦½íŠ¸ (ê°€ì¥ í˜„ì‹¤ì ) â­

```bash
#!/bin/bash
# benchmark_simple.sh - ì§ì ‘ ì‹¤í–‰í•˜ê³  ë¹„êµ

# í…ŒìŠ¤íŠ¸í•  íŒŒë¼ë¯¸í„° ì¡°í•©
ASSEMBLERS=("megahit" "spades")
MIN_CONTIGS=(1500 2000 2500)
BINNERS=("metabat2" "maxbin2")

# ê° ì¡°í•© ì‹¤í–‰
for assembler in "${ASSEMBLERS[@]}"; do
  for min_contig in "${MIN_CONTIGS[@]}"; do
    for binner in "${BINNERS[@]}"; do
      
      # ê²°ê³¼ ë””ë ‰í† ë¦¬
      OUTDIR="results/${assembler}_${min_contig}_${binner}"
      
      # Nextflow ì§ì ‘ ì‹¤í–‰
      echo "Testing: $assembler, $min_contig, $binner"
      
      time nextflow run nf-core/mag \
        -r 3.1.0 \
        --assembler $assembler \
        --min_contig_size $min_contig \
        --binner $binner \
        --input sample_sheet.csv \
        --outdir $OUTDIR \
        -profile singularity \
        -resume
      
      # ê°„ë‹¨í•œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
      echo "$assembler,$min_contig,$binner,$(date)" >> benchmark_log.csv
      
      # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ë¡
      grep "Peak" $OUTDIR/pipeline_info/execution_trace.txt >> benchmark_log.csv
    done
  done
done

# ê²°ê³¼ ìš”ì•½
echo "Benchmark completed. Results in benchmark_log.csv"
```

### ë°©ë²• 2: ê°„ë‹¨í•œ Python ìŠ¤í¬ë¦½íŠ¸ (ë¶„ì„ìš©)

```python
#!/usr/bin/env python3
# analyze_results.py - ê²°ê³¼ ë¶„ì„ë§Œ ë‹´ë‹¹

import pandas as pd
import glob
from pathlib import Path

def analyze_benchmark_results():
    """ì‹¤í–‰ ê²°ê³¼ ë¶„ì„"""
    
    results = []
    
    # ê° ê²°ê³¼ ë””ë ‰í† ë¦¬ ë¶„ì„
    for result_dir in glob.glob("results/*"):
        # ë””ë ‰í† ë¦¬ ì´ë¦„ì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        params = Path(result_dir).name.split('_')
        
        # MultiQC ë¦¬í¬íŠ¸ì—ì„œ ë©”íŠ¸ë¦­ ì¶”ì¶œ
        metrics = {
            'assembler': params[0],
            'min_contig': params[1],
            'binner': params[2]
        }
        
        # BUSCO ê²°ê³¼ ì½ê¸°
        busco_file = f"{result_dir}/QC_shortreads/BUSCO/busco_summary.tsv"
        if Path(busco_file).exists():
            busco_df = pd.read_csv(busco_file, sep='\t')
            metrics['completeness'] = busco_df['Complete'].mean()
        
        # ì‹¤í–‰ ì‹œê°„ ì½ê¸°
        trace_file = f"{result_dir}/pipeline_info/execution_trace.txt"
        if Path(trace_file).exists():
            trace_df = pd.read_csv(trace_file, sep='\t')
            metrics['total_time'] = trace_df['realtime'].sum()
            metrics['peak_memory'] = trace_df['peak_rss'].max()
        
        results.append(metrics)
    
    # ê²°ê³¼ í…Œì´ë¸” ìƒì„±
    df = pd.DataFrame(results)
    
    # ìµœì  ì¡°í•© ì°¾ê¸°
    best_by_completeness = df.nlargest(1, 'completeness')
    best_by_speed = df.nsmallest(1, 'total_time')
    
    print("Best by completeness:")
    print(best_by_completeness)
    print("\nBest by speed:")
    print(best_by_speed)
    
    # CSVë¡œ ì €ì¥
    df.to_csv('benchmark_analysis.csv', index=False)
    
    return df

if __name__ == "__main__":
    analyze_benchmark_results()
```

### ë°©ë²• 3: Nextflow ìì²´ ê¸°ëŠ¥ í™œìš©

```groovy
// benchmark.nf - Nextflowë¡œ ì§ì ‘ ë²¤ì¹˜ë§ˆí‚¹

params.assemblers = ['megahit', 'spades']
params.min_contigs = [1500, 2000, 2500]
params.binners = ['metabat2', 'maxbin2']

// íŒŒë¼ë¯¸í„° ì¡°í•© ìƒì„±
parameter_combinations = []
params.assemblers.each { assembler ->
    params.min_contigs.each { min_contig ->
        params.binners.each { binner ->
            parameter_combinations << [
                assembler: assembler,
                min_contig: min_contig,
                binner: binner
            ]
        }
    }
}

// ê° ì¡°í•©ì— ëŒ€í•´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
workflow {
    Channel
        .from(parameter_combinations)
        .map { combo ->
            // MAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            RUN_MAG(
                params.input,
                combo.assembler,
                combo.min_contig,
                combo.binner
            )
        }
        .collect()
        .map { results ->
            // ê²°ê³¼ ë¹„êµ
            COMPARE_RESULTS(results)
        }
}
```

## 3. ì‹¤ì œë¡œ ì§€ê¸ˆ ë‹¹ì¥ í•  ìˆ˜ ìˆëŠ” ê²ƒ

### Step 1: í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
```bash
# ì‘ì€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë§Œë“¤ê¸°
head -n 100000 ERR599039_1.fastq > test_R1.fastq
head -n 100000 ERR599039_2.fastq > test_R2.fastq
```

### Step 2: 2-3ê°œ ì¡°í•©ë§Œ í…ŒìŠ¤íŠ¸
```bash
# ì¡°í•© 1: ë¹ ë¥¸ ì‹¤í–‰
nextflow run nf-core/mag \
  --assembler megahit \
  --min_contig_size 1500 \
  --binner metabat2 \
  --outdir results/fast \
  --max_memory 32GB

# ì¡°í•© 2: ì •í™•ë„ ìš°ì„ 
nextflow run nf-core/mag \
  --assembler spades \
  --min_contig_size 2500 \
  --binner concoct \
  --outdir results/accurate \
  --max_memory 150GB
```

### Step 3: ê°„ë‹¨ ë¹„êµ
```bash
# ì‹¤í–‰ ì‹œê°„ ë¹„êµ
grep "Completed" results/*/pipeline_info/execution_report.html

# ì–´ì…ˆë¸”ë¦¬ í†µê³„ ë¹„êµ
grep "N50" results/*/Assembly/QC/quast_summary.tsv

# ë¹„ë‹ ê²°ê³¼ ë¹„êµ
wc -l results/*/GenomeBinning/bin_summary.tsv
```

## 4. ë³µì¡í•œ ë„êµ¬ê°€ í•„ìš”í•œ ì‹œì 

### ì§€ê¸ˆì€ ë¶ˆí•„ìš”
- íŒŒë¼ë¯¸í„° ì¡°í•©ì´ 10ê°œ ë¯¸ë§Œ
- ìˆ˜ë™ìœ¼ë¡œ ì¶©ë¶„íˆ ê´€ë¦¬ ê°€ëŠ¥
- ê²°ê³¼ ë¹„êµê°€ ë‹¨ìˆœí•¨

### ë‚˜ì¤‘ì— í•„ìš”í•  ë•Œ
- íŒŒë¼ë¯¸í„° ì¡°í•©ì´ 100ê°œ ì´ìƒ
- ì—¬ëŸ¬ í”„ë¡œì íŠ¸ì—ì„œ ë°˜ë³µ ì‚¬ìš©
- ìë™í™”ëœ ì˜ì‚¬ê²°ì •ì´ í•„ìš”
- íŒ€ ë‹¨ìœ„ ì‚¬ìš©

## 5. ê¶Œì¥ ì ‘ê·¼ë²•

### 1ë‹¨ê³„: ìˆ˜ë™ í…ŒìŠ¤íŠ¸ (í˜„ì¬)
```bash
# ì§ì ‘ ì‹¤í–‰í•˜ê³  ì—‘ì…€ì— ê¸°ë¡
./run_test_1.sh
./run_test_2.sh
# ê²°ê³¼ë¥¼ benchmark_results.xlsxì— ìˆ˜ë™ ì…ë ¥
```

### 2ë‹¨ê³„: ê°„ë‹¨í•œ ìë™í™” (í•„ìš”ì‹œ)
```bash
# ë°˜ë³µ ì‘ì—…ë§Œ ìŠ¤í¬ë¦½íŠ¸ë¡œ
for param in 1500 2000 2500; do
    ./run_with_param.sh $param
done
```

### 3ë‹¨ê³„: ë¶„ì„ ë„êµ¬ (ë°ì´í„° ìŒ“ì¸ í›„)
```python
# ìŒ“ì¸ ë°ì´í„° ë¶„ì„
import pandas as pd
df = pd.read_csv('all_results.csv')
df.groupby('assembler')['completeness'].mean()
```

## 6. ê²°ë¡ 

### âŒ ì§€ê¸ˆ í•˜ì§€ ë§ì•„ì•¼ í•  ê²ƒ
- ë³µì¡í•œ SDK/API êµ¬ì¶•
- ê³¼ë„í•œ ì¶”ìƒí™” ë ˆì´ì–´
- Nextflowë¥¼ ê°ì‹¸ëŠ” Python wrapper
- ë²”ìš© ë²¤ì¹˜ë§ˆí¬ í”„ë ˆì„ì›Œí¬

### âœ… ì§€ê¸ˆ í•´ì•¼ í•  ê²ƒ
1. **ì§ì ‘ ì‹¤í–‰**: `nextflow run` ëª…ë ¹ì–´ ì§ì ‘ ì‚¬ìš©
2. **ê°„ë‹¨ ê¸°ë¡**: ì—‘ì…€ì´ë‚˜ CSVì— ê²°ê³¼ ê¸°ë¡
3. **ìˆ˜ë™ ë¹„êµ**: 2-3ê°œ ì¡°í•©ë§Œ ë¹„êµ
4. **ì ì§„ì  ê°œì„ **: í•„ìš”í•  ë•Œë§Œ ìë™í™” ì¶”ê°€

### ğŸ¯ í•µì‹¬ ì›ì¹™
> "Premature optimization is the root of all evil" - Donald Knuth

ì§€ê¸ˆì€ ë‹¨ìˆœí•˜ê²Œ, ë‚˜ì¤‘ì— í•„ìš”í•˜ë©´ ë³µì¡í•˜ê²Œ!

## 7. ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì‹¤ìš© ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# quick_benchmark.sh - 30ë¶„ ì•ˆì— ê²°ê³¼ í™•ì¸

echo "Quick Benchmark Starting..."

# ì˜µì…˜ 1 ì‹¤í–‰
echo "Testing Option 1: Fast mode"
/usr/bin/time -v nextflow run nf-core/mag \
    --assembler megahit \
    --outdir results/option1 \
    -profile test,singularity \
    2>&1 | tee option1.log

# ì˜µì…˜ 2 ì‹¤í–‰  
echo "Testing Option 2: Accurate mode"
/usr/bin/time -v nextflow run nf-core/mag \
    --assembler spades \
    --outdir results/option2 \
    -profile test,singularity \
    2>&1 | tee option2.log

# ê²°ê³¼ ìš”ì•½
echo "=== RESULTS ==="
echo "Option 1 time: $(grep "Elapsed" option1.log)"
echo "Option 2 time: $(grep "Elapsed" option2.log)"
echo "Option 1 memory: $(grep "Maximum" option1.log)"
echo "Option 2 memory: $(grep "Maximum" option2.log)"

echo "Done! Check results/ directory for details"
```

**ì´ê²Œ ì§„ì§œ í˜„ì‹¤ì ì¸ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤!**